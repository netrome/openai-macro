//! # Ollama Example
//!
//! This example demonstrates how to use the openai-macro with Ollama,
//! a local LLM server that provides OpenAI-compatible APIs.
//!
//! ## Setup
//!
//! 1. Install and start Ollama:
//!    ```bash
//!    # Install Ollama (see https://ollama.com)
//!    ollama serve
//!    ```
//!
//! 2. Pull a coding model:
//!    ```bash
//!    ollama pull codellama       # Good for code generation
//!    # or
//!    ollama pull deepseek-coder  # Alternative coding model
//!    # or
//!    ollama pull llama3.1        # General purpose model
//!    ```
//!
//! 3. Run this example:
//!    ```bash
//!    export LLM_BASE_URL=http://localhost:11434/v1
//!    cargo run --example ollama-example
//!    ```
//!
//! Note: No API key is required for local Ollama instances.

use llimp::llimp;

/// A trait for file system operations
trait FileSystem {
    fn create_directory(&self, path: &str) -> Result<String, String>;
    fn list_files(&self, directory: &str) -> Vec<String>;
    fn get_file_size(&self, path: &str) -> Option<u64>;
}

/// A mock file system implementation
struct MockFileSystem;

#[llimp(prompt = "Implement a mock file system that simulates basic operations. Use realistic behavior and return appropriate success/error messages.")]
impl FileSystem for MockFileSystem {
    fn create_directory(&self, path: &str) -> Result<String, String> {
        // Implementation will be generated by LLM
    }

    fn list_files(&self, directory: &str) -> Vec<String> {
        // Implementation will be generated by LLM
    }

    fn get_file_size(&self, path: &str) -> Option<u64> {
        // Implementation will be generated by LLM
    }
}

/// A trait for data processing operations
trait DataProcessor {
    fn parse_csv_line(&self, line: &str) -> Vec<String>;
    fn calculate_hash(&self, data: &str) -> String;
    fn compress_string(&self, input: &str) -> String;
}

/// A data processor implementation
struct SimpleDataProcessor;

#[llimp(prompt = "Implement data processing functions using standard library only. For CSV parsing, handle quoted fields. For hash, use a simple algorithm. For compression, use a basic run-length encoding.")]
impl DataProcessor for SimpleDataProcessor {
    fn parse_csv_line(&self, line: &str) -> Vec<String> {
        // Implementation will be generated by LLM
    }

    fn calculate_hash(&self, data: &str) -> String {
        // Implementation will be generated by LLM
    }

    fn compress_string(&self, input: &str) -> String {
        // Implementation will be generated by LLM
    }
}

/// A trait for mathematical operations beyond basic arithmetic
trait AdvancedMath {
    fn factorial(&self, n: u64) -> u64;
    fn fibonacci(&self, n: u32) -> u64;
    fn is_prime(&self, n: u64) -> bool;
    fn gcd(&self, a: u64, b: u64) -> u64;
}

/// An advanced math implementation
struct MathUtils;

#[llimp(prompt = "Implement mathematical functions efficiently. Use iterative approaches where possible to avoid stack overflow.")]
impl AdvancedMath for MathUtils {
    fn factorial(&self, n: u64) -> u64 {
        // Implementation generated by LLM
    }

    fn fibonacci(&self, n: u32) -> u64 {
        // Implementation will be generated by LLM
    }

    fn is_prime(&self, n: u64) -> bool {
        // Implementation will be generated by LLM
    }

    fn gcd(&self, a: u64, b: u64) -> u64 {
        // Implementation will be generated by LLM
    }
}

fn main() {
    println!("🦙 Ollama + LLImp Example");
    println!("================================");

    // Check if we're configured for Ollama
    match std::env::var("LLM_BASE_URL") {
        Ok(url) if url.contains("localhost") || url.contains("11434") => {
            println!("✅ Configured for Ollama: {}", url);
        }
        Ok(url) => {
            println!("⚠️  Using external API: {}", url);
        }
        Err(_) => {
            println!("⚠️  No LLM_BASE_URL set. Using default (Google API).");
            println!("   To use Ollama, set: export LLM_BASE_URL=http://localhost:11434/v1");
        }
    }

    println!();

    // Test file system operations
    println!("📁 Testing File System Operations:");
    let fs = MockFileSystem;

    match fs.create_directory("/tmp/test") {
        Ok(msg) => println!("  ✅ Create directory: {}", msg),
        Err(err) => println!("  ❌ Create directory failed: {}", err),
    }

    let files = fs.list_files("/home/user");
    println!("  📋 Files in /home/user: {:?}", files);

    if let Some(size) = fs.get_file_size("/etc/passwd") {
        println!("  📏 Size of /etc/passwd: {} bytes", size);
    } else {
        println!("  ❌ Could not get size of /etc/passwd");
    }

    println!();

    // Test data processing
    println!("🔄 Testing Data Processing:");
    let processor = SimpleDataProcessor;

    let csv_line = "John,Doe,\"Software Engineer\",\"San Francisco, CA\"";
    let parsed = processor.parse_csv_line(csv_line);
    println!("  📊 Parsed CSV: {:?}", parsed);

    let hash = processor.calculate_hash("Hello, Ollama!");
    println!("  🔐 Hash of 'Hello, Ollama!': {}", hash);

    let compressed = processor.compress_string("aaabbbcccdddd");
    println!("  🗜️  Compressed 'aaabbbcccdddd': {}", compressed);

    println!();

    // Test advanced math
    println!("🧮 Testing Advanced Math:");
    let math = MathUtils;

    println!("  🔢 Factorial of 5: {}", math.factorial(5));
    println!("  🌀 Fibonacci of 10: {}", math.fibonacci(10));
    println!("  🔍 Is 17 prime? {}", math.is_prime(17));
    println!("  ➗ GCD of 48 and 18: {}", math.gcd(48, 18));

    println!();
    println!(
        "🎉 Example completed! All implementations were generated by your local LLM instance."
    );

    // Performance note
    println!();
    println!("💡 Performance Tips:");
    println!("   - First run may be slower as implementations are generated and cached");
    println!("   - Subsequent runs use cached implementations and are much faster");
    println!("   - Use LLM_OFFLINE=1 to only use cached implementations");
}

// Tests are disabled for Ollama example to avoid compilation issues
// when LLM implementations are not available
#[cfg(all(test, feature = "enable-ollama-tests"))]
mod tests {
    use super::*;

    #[test]
    #[ignore = "Requires LLM implementations to be generated"]
    fn test_file_system() {
        let fs = MockFileSystem;

        // Test directory creation
        let result = fs.create_directory("/test/path");
        assert!(result.is_ok() || result.is_err()); // Just ensure it returns something

        // Test file listing
        let files = fs.list_files("/");
        assert!(files.len() >= 0); // Should return a vector (possibly empty)
    }

    #[test]
    #[ignore = "Requires LLM implementations to be generated"]
    fn test_data_processor() {
        let processor = SimpleDataProcessor;

        // Test CSV parsing
        let parsed = processor.parse_csv_line("a,b,c");
        assert!(parsed.len() > 0);

        // Test hash calculation
        let hash1 = processor.calculate_hash("test");
        let hash2 = processor.calculate_hash("test");
        assert_eq!(hash1, hash2); // Same input should produce same hash

        let hash3 = processor.calculate_hash("different");
        assert_ne!(hash1, hash3); // Different input should produce different hash
    }

    #[test]
    #[ignore = "Requires LLM implementations to be generated"]
    fn test_advanced_math() {
        let math = MathUtils;

        // Test factorial
        assert_eq!(math.factorial(0), 1);
        assert_eq!(math.factorial(1), 1);

        // Test fibonacci
        assert_eq!(math.fibonacci(0), 0);
        assert_eq!(math.fibonacci(1), 1);

        // Test prime checking
        assert!(!math.is_prime(1));
        assert!(math.is_prime(2));
        assert!(math.is_prime(3));
        assert!(!math.is_prime(4));

        // Test GCD
        assert_eq!(math.gcd(0, 5), 5);
        assert_eq!(math.gcd(5, 0), 5);
        assert_eq!(math.gcd(12, 8), 4);
    }
}
